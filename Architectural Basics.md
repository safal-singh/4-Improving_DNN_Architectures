# ARCHITECTURAL BASICS

The order to consider for designing deep networks' architecture - <br/>
1. Receptive field
2. Number of layers
3. 3x3 convolutions
4. Softmax
5. Kernels and their number
6. Max Pooling 
7. Position of max pooling
8. Max pooling distance from prediction
9. 1x1 convolutions
10. Transitions layers
11. Position of transition layers
12. Image Normalization
13. Batch Normalization
14. Distance of batch normalization from prediction
15. Number of epochs and increasing them if training accuracy has not converged.
16. Checking accuracy on validation data for every epoch
17. Dropout when the network is overfitting (difference between training and validation accuracies is large)
18. Learning rate
19. Adam or SGD




Learning Rate,
When do we stop convolutions and go ahead with a larger kernel or some other alternative (which we have not yet covered)
How do we know our network is not going well, comparatively, very early
Batch Size, and effects of batch size
LR schedule and concept behind it
Adam vs SGD
etc (you can add more if we missed it here)

